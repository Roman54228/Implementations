{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l5PnJt03Cj8"
      },
      "source": [
        "# Early Stopping Example\n",
        "In this notebook, we will train an Multi-Layer Perceptron (MLP) to classify images from the [MNIST database](http://yann.lecun.com/exdb/mnist/) hand-written digit database, and use early stopping to stop the training when the model starts to overfit to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "doiyxLLA3CkG"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp0JySZM3CkJ"
      },
      "source": [
        "### Load and Batch the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AB5R8BIf3CkK"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "def create_datasets(batch_size):\n",
        "    valid_size = 0.2\n",
        "\n",
        "    transform = transforms.ToTensor()\n",
        "\n",
        "    train_data = datasets.MNIST(root='data', \n",
        "                                train=True,\n",
        "                                download=True, \n",
        "                                transform=transform)\n",
        "\n",
        "    test_data = datasets.MNIST(root='data',\n",
        "                               train=False,\n",
        "                               download=True,\n",
        "                               transform=transform)\n",
        "\n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    \n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               sampler=train_sampler,\n",
        "                                               num_workers=0)\n",
        "    valid_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               sampler=valid_sampler,\n",
        "                                               num_workers=0)\n",
        "    \n",
        "    test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                              batch_size=batch_size,\n",
        "                                              num_workers=0)\n",
        "    \n",
        "    return train_loader, test_loader, valid_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc2BjrPq3CkM"
      },
      "source": [
        "### Define the Network\n",
        "Defining a simple MLP model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Z-gmOIZB3CkN",
        "outputId": "7c125bdc-4654-4ab0-e655-a628deebde58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXwCA79j3CkO"
      },
      "source": [
        "### Specify Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FERBV3DA3CkP"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijO2mMEk3CkQ"
      },
      "source": [
        "### Import the Early Stopping Class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "0wJuPu923a2J"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZTUEtPqu3CkR"
      },
      "outputs": [],
      "source": [
        "# import EarlyStopping\n",
        "#from pytorchtools import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwxOtEOZ3CkR"
      },
      "source": [
        "### Train the Model using Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TbQ4WCmW3CkS"
      },
      "outputs": [],
      "source": [
        "def train_model(model, batch_size, patience, n_epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    avg_train_losses = []\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "        for batch, (data, target) in enumerate(train_loader, 1):\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval() \n",
        "        for data, target in valid_loader:\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'valid_loss: {valid_loss:.5f}')\n",
        "        \n",
        "        print(print_msg)\n",
        "        \n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return  model, avg_train_losses, avg_valid_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy7bZ-0B3CkT",
        "outputId": "51cb4d8d-ecbd-4a37-c31b-d145162148ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/100] train_loss: 0.81920 valid_loss: 0.29474\n",
            "Validation loss decreased (inf --> 0.294738).  Saving model ...\n",
            "[  2/100] train_loss: 0.36657 valid_loss: 0.21378\n",
            "Validation loss decreased (0.294738 --> 0.213784).  Saving model ...\n",
            "[  3/100] train_loss: 0.29468 valid_loss: 0.17844\n",
            "Validation loss decreased (0.213784 --> 0.178439).  Saving model ...\n",
            "[  4/100] train_loss: 0.25470 valid_loss: 0.15887\n",
            "Validation loss decreased (0.178439 --> 0.158866).  Saving model ...\n",
            "[  5/100] train_loss: 0.22781 valid_loss: 0.14919\n",
            "Validation loss decreased (0.158866 --> 0.149195).  Saving model ...\n",
            "[  6/100] train_loss: 0.20899 valid_loss: 0.13427\n",
            "Validation loss decreased (0.149195 --> 0.134267).  Saving model ...\n",
            "[  7/100] train_loss: 0.19464 valid_loss: 0.12291\n",
            "Validation loss decreased (0.134267 --> 0.122913).  Saving model ...\n",
            "[  8/100] train_loss: 0.17921 valid_loss: 0.11812\n",
            "Validation loss decreased (0.122913 --> 0.118124).  Saving model ...\n",
            "[  9/100] train_loss: 0.16977 valid_loss: 0.11898\n",
            "EarlyStopping counter: 1 out of 20\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "n_epochs = 100\n",
        "\n",
        "train_loader, test_loader, valid_loader = create_datasets(batch_size)\n",
        "\n",
        "patience = 20\n",
        "\n",
        "model, train_loss, valid_loss = train_model(model, batch_size, patience, n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYCw7KJ23CkT"
      },
      "source": [
        "### Visualizing the Loss and the Early Stopping Checkpoint\n",
        "From the plot we can see that the last Early Stopping Checkpoint was saved right before the model started to overfit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "03S5cG823CkU",
        "outputId": "f1b08f40-7424-42e6-93da-dd87c99dd22a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 0.5) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('loss_plot.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C9kXiYq3CkU"
      },
      "source": [
        "### Test the Trained Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tpNRMfMS3CkU",
        "outputId": "7f647d50-c94d-4520-fec6-f00543e4cd0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.299962\n",
            "\n",
            "Test Accuracy of     0:  0% ( 0/979)\n",
            "Test Accuracy of     1:  0% ( 0/1133)\n",
            "Test Accuracy of     2: 88% (909/1030)\n",
            "Test Accuracy of     3:  9% (97/1008)\n",
            "Test Accuracy of     4:  0% ( 0/980)\n",
            "Test Accuracy of     5:  0% ( 0/890)\n",
            "Test Accuracy of     6:  0% ( 0/956)\n",
            "Test Accuracy of     7:  0% ( 2/1027)\n",
            "Test Accuracy of     8:  0% ( 0/973)\n",
            "Test Accuracy of     9:  2% (23/1008)\n",
            "\n",
            "Test Accuracy (Overall): 10% (1031/9984)\n"
          ]
        }
      ],
      "source": [
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval() # prep model for evaluation\n",
        "\n",
        "for data, target in test_loader:\n",
        "    if len(target.data) != batch_size:\n",
        "        break\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(batch_size):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dSKFc-r3CkW"
      },
      "source": [
        "### Visualize Sample Test Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HmiGzyvt3CkW",
        "outputId": "2aa29c0b-0651-4650-d1c3-0bf4fedf1f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-48bf1d79b703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# obtain one batch of test images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# get sample outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
          ]
        }
      ],
      "source": [
        "# obtain one batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds = torch.max(output, 1)\n",
        "# prep images for display\n",
        "images = images.numpy()\n",
        "\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okpfWuZY3CkW"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYZO-tj53CkX"
      },
      "source": [
        "The MNIST training example code is mainly taken from the [mnist_mlp_solution_with_validation.ipynb](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/convolutional-neural-networks/mnist-mlp/mnist_mlp_solution_with_validation.ipynb) notebook from the [deep-learning-v2-pytorch repository](https://github.com/udacity/deep-learning-v2-pytorch) made by [Udacity](https://www.udacity.com/), and has been fitted with my early stopping code. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}